# beautiful-data-project-enigma
Q1.) What question(s) did you decide to work on as a team?

Ans-We want to figure out what might be the next language that will trend up and why?

Q2.) What is your data source(s)?

Ans-https://archive.org/details/stackexchange.

Twitter live tweets API

Q3.) How long does it take for you to download data? Have you download complete data set?

Ans-It took us about 14 hours to download the entire data set from https://archive.org/details/stackexchange. 
That is the complete data set we have from the stackexchange website.
As for Twitter api, we are getting the real time data.

Q4.) How large is your data (size wise and number of records wise)?

Ans-41 GB total raw data.

Q5.)Do you face any dirty data issue? If you do, how did you clean up your data?

Ans-Yes, data has some null value sometimes. We found some missing records and we have to manually remove them out.

Q6.) How do you store the data you downloaded?
Ans-We store all the data in the mongoDB.

